[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "You can find some of my earlier writing in Medium."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vignesh Gopakumar",
    "section": "",
    "text": "I am a Research Scientist at the UK Atomic Energy Authority (UKAEA), where I lead a team developing “actionable” surrogate models for exascale simulations and data-driven models for the Fusion industry. My research focusses on enhancing machine learning models’ performance, robustness and interpretability through physics-based approaches.\nI am also a visiting researcher with the SciML group at STFC’s Rutherford Appleton Laboratory.\nConcurrently, I’m pursuing a PhD in Machine Learning under Marc Deisenroth at University College London.\n\n\nCurrent Research:\n\nPhysics-Informed Machine Learning\nContinuous Dynamics Modelling\nUncertainty Quantification\nDesign of Experiments\n\nBuilding simvue.io : AI-driven, open-source simulation management and tracking dashboard for streamlining engineering workflows. Developed with public funding from the UK Government. Currently in private \\(\\beta\\).\n\n“If there is a God, it must be a differential equation” - Bertrand Russell"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "On Surrogate Modelling for Fusion - PhysicsX (London 2024)\nFNO for Plasma Modelling (Invited) - IAEA Workshop on AI for Accelerating Fusion and Plasma Science (Vienna 2023)\nFNO for Plasma Modelling - IAEA Fusion Energy Conference (London, 2023)\nFNO for Plasma Modelling - AI for sustainability workshop @ UCL (London, 2023)\nFourier RNNs for modelling noisy physics data - IEEE ICMLA (Bahamas, 2022)\nInformed Sampling of the Plasma Hyperspace for Digital Twinning - IAEA Fusion Data Processing, Validation, Analysis (Chengdu, 2021)\nOptimising Physics Informed Neural Networks - PyTorch Ecosystem Day (Virtual, 2021)\nFluid Surrogates using Neural PDEs - SciML at RAL, STFC (Oxford, 2020)\nSolving Fluid Dynamics with Neural Networks - FusionEP (Virtual, 2020)\nData Driven Modelling of Plasma in Tokamaks - IOP Physics in the spotlight (London, 2019)\nData Driven Modelling and Control of Plasma in Fusion Reactors - O’Reilly AI London (London, 2019)"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Research",
    "section": "",
    "text": "2024\n\n\nUncertainty Quantification of surrogate Models using Conformal Prediction\n\nAuthors: Vignesh Gopakumar, Ander Gray, Joel Oskarsson, Lorenzo Zanisi, Stanislas Pamela, Daniel Giles, Matt J. Kusner, Marc Peter Deisenroth\nPublished in: arXiv preprint arXiv:2408.09881, 2024\nTLDR: Guaranteed and valid error bars across spatio-temporal domains using conformal prediction.\nPaper Code\n\n\n\nValid Error Bars for Neural Weather Models using Conformal Prediction\n\nAuthors: Vignesh Gopakumar, Ander Gray, Joel Oskarsson, Lorenzo Zanisi, Stanislas Pamela, Daniel Giles, Matt J. Kusner, Marc Peter Deisenroth\nPublished in: arXiv preprint arXiv:2406.14483, 2024\nTLDR: Marginal conformal prediction as a method of guaranteed error bars across neural weather models.\n\nPaper Code\n\n\n\nPlasma Surrogate Modelling using Fourier Neural Operators\n\nAuthors: Vignesh Gopakumar, Stanislas Pamela, Lorenzo Zanisi, Zongyi Li, Ander Gray, Daniel Brennand, Nitesh Bhatia, Gregory Stathopoulos, Matt Kusner, Marc Peter Deisenroth, Anima Anandkumar, JOREK Team, MAST Team\nPublished in: Nuclear Fusion, Volume 64, Number 5, 2024\nTLDR: Multi-variable FNO designed to model the plasma evolution within a Tokamak across both simulations and experiment on the MAST Tokamak.\nPaper Code\n\n\n\n\n2023\n\n\nFourier-RNNs for Modelling Noisy Physics data\n\nAuthors: Vignesh Gopakumar, Lorenzo Zanisi, Stanislas Pamela\nPublished in: arXiv preprint arXiv:2302.06534, 2023\nTLDR: Recurrent Fourier neural operators with hidden state representations for non-markovian physcial modelling.\nPaper\n\n\n\nLoss Landscape Engineering via Data Regulation on PINNs\n\nAuthors: Vignesh Gopakumar, Stanislas Pamela, Debasmita Samaddar\nPublished in: Machine Learning with Applications, Volume 12, 2023\nTLDR: Impact Data-Regulation has on smoothening the loss landscape of physics-informed neural networks for better convergence.\nPaper Code\n\n\n\n\n2022\n\n\nImage Mapping the Temporal Evolution of Edge Characteristics in Tokamaks using Neural Networks\n\nAuthors: Vignesh Gopakumar, Debasmita Samaddar\nPublished in: Machine Learning: Science and Technology, Volume 1, Number 1, 2020\nTLDR: Branched fully convolutional network designed to emulate the plasma at the scrape-off layer with coupled plasma and neutral behaviour.\nPaper\n\n\n\n\nYou can find the latest list of publications in my google scholar page."
  },
  {
    "objectID": "Neural_ODE.html",
    "href": "Neural_ODE.html",
    "title": "Neural ODEs",
    "section": "",
    "text": "Markdown is an easy to read and write text format:\n\nIt’s plain text so works well with version control\nIt can be rendered into HTML, PDF, and more\nLearn more at: https://quarto.org/docs/authoring/"
  },
  {
    "objectID": "Neural_ODE.html#markdown",
    "href": "Neural_ODE.html#markdown",
    "title": "Neural ODEs",
    "section": "",
    "text": "Markdown is an easy to read and write text format:\n\nIt’s plain text so works well with version control\nIt can be rendered into HTML, PDF, and more\nLearn more at: https://quarto.org/docs/authoring/"
  },
  {
    "objectID": "Neural_ODE.html#code-cell",
    "href": "Neural_ODE.html#code-cell",
    "title": "Neural ODEs",
    "section": "Code Cell",
    "text": "Code Cell\nHere is a Python code cell:\n\nimport os\nos.cpu_count()\n\n12"
  },
  {
    "objectID": "Neural_ODE.html#equation",
    "href": "Neural_ODE.html#equation",
    "title": "Neural ODEs",
    "section": "Equation",
    "text": "Equation\nUse LaTeX to write equations:\n\\[\n\\Sigma = \\sum_{i=1}^n k_i s_i^2\n\\]"
  },
  {
    "objectID": "blogposts/Neural_ODE.html",
    "href": "blogposts/Neural_ODE.html",
    "title": "Neural ODEs",
    "section": "",
    "text": "Original Paper\nNeural ODE, introduced in (Chen et al. 2019)\n\n\n\n\n\n\nReferences\n\nChen, Ricky T. Q., Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. 2019. “Neural Ordinary Differential Equations.” https://arxiv.org/abs/1806.07366."
  },
  {
    "objectID": "blogposts/Neural_ODE.html#markdown",
    "href": "blogposts/Neural_ODE.html#markdown",
    "title": "Neural ODEs",
    "section": "",
    "text": "Markdown is an easy to read and write text format:\n\nIt’s plain text so works well with version control\nIt can be rendered into HTML, PDF, and more\nLearn more at: https://quarto.org/docs/authoring/"
  },
  {
    "objectID": "blogposts/Neural_ODE.html#code-cell",
    "href": "blogposts/Neural_ODE.html#code-cell",
    "title": "Neural ODEs",
    "section": "Code Cell",
    "text": "Code Cell\nHere is a Python code cell:\n\nimport os\nos.cpu_count()\n\n12"
  },
  {
    "objectID": "blogposts/Neural_ODE.html#equation",
    "href": "blogposts/Neural_ODE.html#equation",
    "title": "Neural ODEs",
    "section": "Equation",
    "text": "Equation\nUse LaTeX to write equations:\n\\[\n\\Sigma = \\sum_{i=1}^n k_i s_i^2\n\\]"
  },
  {
    "objectID": "blogposts/Neural_ODE.html#original-paper",
    "href": "blogposts/Neural_ODE.html#original-paper",
    "title": "Neural ODEs",
    "section": "",
    "text": "Markdown is an easy to read and write text format:\n\nIt’s plain text so works well with version control\nIt can be rendered into HTML, PDF, and more\nLearn more at: https://quarto.org/docs/authoring/"
  },
  {
    "objectID": "Blogposts/Neural_ODE.html",
    "href": "Blogposts/Neural_ODE.html",
    "title": "Neural ODEs",
    "section": "",
    "text": "Original Paper\nNeural ODE, introduced in (Chen et al. 2019),\n\n\n\n\n\n\nReferences\n\nChen, Ricky T. Q., Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. 2019. “Neural Ordinary Differential Equations.” https://arxiv.org/abs/1806.07366."
  },
  {
    "objectID": "Blog/Neural_ODE.html",
    "href": "Blog/Neural_ODE.html",
    "title": "Neural ODEs",
    "section": "",
    "text": "Neural ODE, introduced in (Chen et al. 2019), represents a class of neural networks capable of performing continuous dynamics modelling. Based on the idea that resnets and recurrent models operate with transformations in the hidden state \\[h_{t+1}= h_t + f(h_t, \\theta_t), \\; \\text{as} \\; \\Delta t \\rightarrow 0,\\] the neural network parameterises the continous dynamics of an ODE \\[\\frac{dh(t)}{dt} = f(h(t), t, \\theta)\\].\nThe key contributions from this paper are:\n1. Modelling continous dynamics \n2. Obeying an Ordinary Differential Equation (ODE)\n3. Using the adjoint-method to scale to deeper and more complex networks without memory constraints. \nBefore we dive into the details of this work. Lets take a look at what it means to have a neural network to obey an ODE.\nODEs are solved as a systems of linear equations Here is a Python code cell:\n\nimport os\nos.cpu_count()\n\n12\n\n\n\n\n\n\nReferences\n\nChen, Ricky T. Q., Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. 2019. “Neural Ordinary Differential Equations.” https://arxiv.org/abs/1806.07366."
  },
  {
    "objectID": "Blog/Neural_Operators.html",
    "href": "Blog/Neural_Operators.html",
    "title": "Neural ODEs",
    "section": "",
    "text": "Neural ODE, introduced in (Chen et al. 2019), represents a class of neural networks capable of performing continuous dynamics modelling. Based on the idea that resnets and recurrent models operate with transformations in the hidden state \\[h_{t+1}= h_t + f(h_t, \\theta_t), \\; \\text{as} \\; \\Delta t \\rightarrow 0,\\] the neural network parameterises the continous dynamics of an ODE \\[\\frac{dh(t)}{dt} = f(h(t), t, \\theta)\\].\nThe key contributions from this paper are:\n1. Modelling continous dynamics \n2. Obeying an Ordinary Differential Equation (ODE)\n3. Using the adjoint-method to scale to deeper and more complex networks without memory constraints. \nBefore we dive into the details of this work. Lets take a look at what it means to have a neural network to obey an ODE.\nODEs are solved as a systems of linear equations Here is a Python code cell:\n\nimport os\nos.cpu_count()\n\n12\n\n\n\n\n\n\nReferences\n\nChen, Ricky T. Q., Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. 2019. “Neural Ordinary Differential Equations.” https://arxiv.org/abs/1806.07366."
  }
]